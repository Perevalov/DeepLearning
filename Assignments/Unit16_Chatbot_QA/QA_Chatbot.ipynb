{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-Answering Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this homework is to build a question-answering Chatbot using a couple of very different deep network architectures (a retrieval architecture, and a generative architecture) as well as a hybrid  of these  architectures. \n",
    "\n",
    "You will be using the **Stanford Question Answering Dataset** or [**SQuAD**](https://rajpurkar.github.io/SQuAD-explorer/) for training and evaluation.\n",
    "\n",
    "In this dataset, utterances are questions and responses are sentence. A typical question-answer pair is of the form:\n",
    "* QUESTION: Where do water droplets collide with ice crystals to form precipitation?\n",
    "* ANSWER: within a cloud\n",
    "\n",
    "For the purposes of this homework, we will be ignoring the context vector in the Q-A pairs.\n",
    "\n",
    "** Evaluation and discussion of this homework assigment **\n",
    "\n",
    "Please complete section 5 of this assigment. If this section is not completed then you can expect **ZERO grade** for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Retrieval-based model for QA-Chatbotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this task it to build a **QA-chatbot** using a **retrieval** model. A suggested way of accomplishing this is to take the provided baseline implementation based on DSSM (described below) and extending it in a number of ways that are detailed below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSSM baseline implementation\n",
    "To solve this problem it is recommended to use an architecture similar to the **Deep Structured Semantic Model** or [**DSSM**](https://www.microsoft.com/en-us/research/project/dssm/) and **Stanford Question Answering Dataset** or [**SQuAD**](https://rajpurkar.github.io/SQuAD-explorer/). We provide a starter notebook on the class GitHub in the Labs subfolder `Unit16_DSSM_IR`. It contains a working baseline for building a DSSM retrieval model with the same dataset. But the performance of the model presented there can be greatly improved. Next is a sketch of some ideas on how one can improve this baseline DSSM model:\n",
    "\n",
    "## Improvement 1: better encoder\n",
    "In the baseline architecture `Unit16_DSSM_IR` we use Global Average Pooling (GAP) as the only encoder layer in both towers. It's quite obvious that the learning capacity of GAP is way too low (it does not even have learnable parameters!). One possible improvment is use more elaborate and learnable layers the encoder phase of the towers. For example, even one-layer LSTM should work much better. As an alternative one can also consider using  [Convolutional](https://arxiv.org/pdf/1705.03122.pdf) or [Attentive](https://arxiv.org/pdf/1706.03762.pdf) encoders which are some of the of state-of-the-art encoders. Other possible improvements  that one can also think of is stacking multiple layers and adding skip-connections between them. Please **dont** limit your exploration to these suggestions.\n",
    "\n",
    "## Improvement 2: better sampling\n",
    "\n",
    "[\"Sampling Matters in Deep Embedding Learning\"](https://arxiv.org/pdf/1706.07567.pdf) - as hightlighted by the name of this recently published paper. In the baseline `Unit16_DSSM_IR` notebook we discussed a few different sampling strategies  like `Easy Negatives`, `Hard Negatives`, `Semi-hard Negatives` etc. But we only used the `easy negatives` sampling strategy which is known to be not very informative. A possible improvement here might be to implement one of the more advanced sampling techniques and see how the quality of the models changes (semi-hard negative should work well from our experience). The performance should change dramatically. \n",
    "\n",
    "### Hybrid sampling strategy\n",
    "\n",
    "An another possible improvement is explore combining different sampling strategies.  For example, one possible hybrid strategy could be the following:\n",
    "\n",
    "* one can start training with `easy negatives` for 10 epochs so the network can learn something; \n",
    "* then switch to the `hard negatives` which could lead to a more agressive and informative stage of the training and\n",
    "* finally switch to the semi-hard negatives which could be viewed as a kind of fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A generative approach for QA-Chatbotting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this task it to build a **chatbot** using a **generative** model.\n",
    "\n",
    "For that purpose you are to use the **Encoder-Decoder Sequence-2-Sequence** model on the same QA-chatbot task (**Stanford Question Answering Dataset** or [**SQuAD**](https://rajpurkar.github.io/SQuAD-explorer/)).\n",
    "\n",
    "One can adapt the same data reading and preprocessing steps that were used in the `Unit16_DSSM_IR` notebook.\n",
    "\n",
    "![seq2seq.png](seq2seq.png)\n",
    "\n",
    "The basic idea behind Encoder-Decoder generative models is to use two different interconnected parts of the network:\n",
    "* **Encoder** is responsible for understanding and encoding the input question\n",
    "* **Decoder** uses the encoded qustion and generate the answer on-the-fly\n",
    "The main difference from the retrieval-based models is that the answer is indeed being generated instead of taking one of the *canned* training responses. [Here](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/) one can read more on the differences between generative and retrieval models.\n",
    "\n",
    "Your task in this homework is to build a generative Encoder-Decoder model. The [following](https://github.com/tensorflow/nmt) tutorial gives a very detailed description of  Encoder-Decoder models and how they can be implemented in Tensorflow (alas). Recently it has [become](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html) possible to build Encoder-Decoder models in pure Keras (yay!). An alternative to pure Keras is to use a thirdparty library such as  [seq2seq](https://github.com/farizrahman4u/seq2seq)). Seq2Seq is built on top of Keras and is  easy to use for Encoder-Decoder architectures. But with a pure Keras implementation one would have more fine-grained control over the model. We recommend you use a pure Keras implementation wherever possible.\n",
    "\n",
    "Many different architecture are possible using a Encoder-Decoder solution. For example, a baseline architecture might be the following:\n",
    "\n",
    "* Embedding layer\n",
    "* One LSTM Encoder layer\n",
    "* One LSTM Decoder layer\n",
    "\n",
    "We can improve this baseline architecture in many ways that are sketched out here (but you are not limited to these. Be brave and try others!):\n",
    "\n",
    "* More complicated Encoder and Decoder. For example, one might consider to use stacked bidirectional LSTMs in the Encoder part (note that one can NOT use bidirectional layers in Decoder) and stacked LSTMs in the Decoder.\n",
    "* Explore using an Attention mechanism from Decoder to Encoder. More theory and intuition behind the attention layer can be found [here](https://distill.pub/2016/augmented-rnns/)\n",
    "* Beam search during the Decoder generation stage instead of simple greedy \"most probable word\" approach can lead to a few percentage points improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A hybrid retrieval and generative approach to QA-Chatbotting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the generative and retrieval approaches have their own merits and limitations when it comes to chatbots. Here is a short list for each approach:\n",
    "* Generative:\n",
    "    * **+** diverse responses which are generated on-the-fly\n",
    "    * **-** responses might sometimes be gramatically incorrect and logically inconsistent\n",
    "* Retrieval:\n",
    "    * **+** gramatically correct and consistent responses as they are chosen from the human-written phrases\n",
    "    * **-** lack of diversity; it's impossible to have ready-to-use phrase for each possible question even with the very huge training set\n",
    "\n",
    "[Here](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/) one can find a more detailed comparison of these approaches. The bottom line here is that these models are good for  different tasks. However, combining the retrieval and generative approaches might lead to the best of both worlds. Let's explore that!\n",
    "\n",
    "Your task here is to come up with a good way to combine the generative and retrieval approaches into one or more networks and implement this solution. \n",
    "\n",
    "## Recommended hybrid architectures\n",
    "\n",
    "[This](https://arxiv.org/abs/1610.07149) paper might be a good  background and starting point for this task.\n",
    "\n",
    "Here are some suggestion candidate architectures (please do NOT limit your exploration to these):\n",
    "* Build and train retrieval and generative models. Get top-N (say 5 or 10) answers from each model. Build a model to re-rank the top 2N answers to find the most suitable one. There are at least two architecture variations here: \n",
    "    * Use DSSM model from retrieval part for the re-ranking purposes\n",
    "    * Build and train a new DSSM model for the re-ranking purposes\n",
    "    \n",
    "* Get top-10 answers with retrieval model and then build a conditional generative model which will modify retrieved answers and thereby generate a more diverse sets of responses. One of the ways to do it is:\n",
    "    * Get top-10 answers from the retrieval model\n",
    "    * Treat these 10 answers and the  question as 10 training pairs for the generative model. Train the generative model on these pairs.\n",
    "    * Build a re-ranking model for the answers of the generative model.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA ChatBot Discussion\n",
    "\n",
    "Please use this section to consolidate the results of all experiments and discuss your findings and recommendations.\n",
    "\n",
    "Please report the following table of performance statistics for each task on the train and validation sets. In addition provide a block diagram detailing the best architecture used for each of the three tasks in this assignment. \n",
    "\n",
    "With regard to a results table, for each of the tasks  please report the following:\n",
    "\n",
    "* Hardware used\n",
    "* Experiment ID\n",
    "* ExactMatch (EM) and F1 scores of the best models on both train and validation set\n",
    "* The duration of training in wallclock time (in seconds)\n",
    "* The duration of validation in wallclock time (in seconds)\n",
    "* Experiment description\n",
    "\n",
    "**Note: ** [This](https://worksheets.codalab.org/rest/bundles/0xbcd57bee090b421c982906709c8c27e1/contents/blob/) python script can be used to produce ExactMatch (EM) and F1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use a logging table structure like this to keep track of your experiments and make sure to embed them in your notebook (along with a brief description and discussion that is provided outside the table!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Hardware\", \"ExpID\", \"EMTrain\", \"F1Train\", \"EMValid\", \"F1Valid\" \"TrainTime(s)\", \"ValidTime(s)\", \"Experiment description\"])\n",
    "\n",
    "results.loc[len(results)] = [\"Blah\", \n",
    "                             np.round(emTrain * 100, 1), \n",
    "                             .........\n",
    "                             expDuration,\n",
    "                             \"Blah\",  \n",
    "                             \"W2V Full Wiki\"]\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "1022px",
    "left": "0px",
    "right": "1560px",
    "top": "106px",
    "width": "334px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
